# ðŸ§  Language Modeling with Unigrams, Bigrams, and Smoothing Techniques

This repository implements core language modeling techniques using unigram and bigram probabilities. It explores classical statistical language models, smoothing strategies, and evaluates performance using sentence log probabilities and perplexity.

---

## ðŸš€ Features

- âœ… Unigram and Bigram Language Models  
- âœ… **Laplace Smoothing (Add-1)**  
- âœ… **Linear Interpolation Smoothing**  
- âœ… Sentence Log Probability Calculation  
- âœ… Perplexity Evaluation (Train, Dev, Test)  
- âœ… OOV Handling (Out-of-Vocabulary Words)

---



